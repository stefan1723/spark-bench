spark-bench = {
  spark-submit-config = [{
    spark-home = "/home/sbora/tmp/spark_2.4.0_additional_logging_dist/spark-2.4.1-SNAPSHOT-bin-custom-spark" // PATH TO YOUR SPARK INSTALLATION
    spark-args = {
      master = "spark://sparkle4:7077" // FILL IN YOUR MASTER HERE
      executor-memory = "2500M" // FILL IN YOUR EXECUTOR MEMORY
      // conf.spark.driver.bindAddress = "172.23.180.51"
      // conf = "spark.driver.host=172.23.180.51"
    }
    conf = {
      // Any configuration you need for your setup goes here, like:
      // "spark.dynamicAllocation.enabled" = "false"
      spark.io.compression.codec = "org.apache.spark.io.LZ4CompressionCodec"
      // spark.driver.bindAddress = "172.23.180.51"
    }
    suites-parallel = false
    workload-suites = [
      {
        save-mode: "overwrite"
        descr = "Run exponential distributed workloads"
        benchmark-output = "hdfs://sparkle1:9000/tmp/output.csv"
        run-mode = "split-merge"
        save-mode = "overwrite"
        repeat = 10
        arrival-distribution = {
          distribution = "exponential"
          mu = 0.2
        }
        workloads = [
          {
            name = "distributed-blocking"
            distribution = "exponential"
            mu = 1.5
          }
        ]
      }
    ]
  }]
}
