spark-bench = {
  spark-submit-config = [{
    spark-home = "/home/sbora/tmp/spark_2.4.0_additional_logging_dist/spark-2.4.1-SNAPSHOT-bin-custom-spark" // PATH TO YOUR SPARK INSTALLATION
    spark-args = {
      master = "spark://sparkle4:7077" // FILL IN YOUR MASTER HERE
      executor-memory = "2500M" // FILL IN YOUR EXECUTOR MEMORY
      // conf.spark.driver.bindAddress = "172.23.180.51"
      // conf = "spark.driver.host=172.23.180.51"
    }
    conf = {
      // Any configuration you need for your setup goes here, like:
      // "spark.dynamicAllocation.enabled" = "false"
      "spark.io.compression.codec" = "org.apache.spark.io.LZ4CompressionCodec"
      // "spark.driver.bindAddress" = "172.23.180.51"
      "spark.eventLog.enabled" = "true"
      "spark.eventLog.dir" = "hdfs://172.23.27.10:9000/eventLog/"
    }
    suites-parallel = false
    workload-suites = [
      {
        save-mode: "overwrite"
        descr = "Run exponential distributed workloads"
        benchmark-output = "hdfs://sparkle1:9000/tmp/output.csv"
        save-mode = "overwrite"
        repeat = 10
        run-mode = "single-queue-fork-join"
        arrival-distribution = {
          distribution = "exponential"
          multiplier = 1000.000001
          mu = 0.5
        }
        workloads = [
          {
            slices = 50
            name = "distributed-blocking"
            distribution = "exponential"
            multiplier = 1000.0000001
            mu = 10.00001
          }
        ]
      }
    ]
  }]
}
